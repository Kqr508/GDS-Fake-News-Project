{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huske at vi skal have en clean data på maskinen for at være i stand til at køre denne kode.\n",
    "# Har skiftet datasæten fra data.csv til cleaned_dataset_FULL.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7444726.0</td>\n",
       "      <td>nationalreview.com</td>\n",
       "      <td>political</td>\n",
       "      <td>http://www.nationalreview.com/node/152734/%E2%...</td>\n",
       "      <td>Plus one article on Google Plus\\n\\n(Thanks to ...</td>\n",
       "      <td>2017-11-27T01:14:42.983556</td>\n",
       "      <td>2018-02-08 19:18:34.468038</td>\n",
       "      <td>2018-02-08 19:18:34.468066</td>\n",
       "      <td>Iran News Round Up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['National Review', 'National Review Online', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['plu', 'one', 'articl', 'googl', 'plu', 'than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6213642.0</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/economy/2012/06/the-c...</td>\n",
       "      <td>The Cost Of The Best Senate Banking Committee ...</td>\n",
       "      <td>2017-11-27T01:14:08.7454</td>\n",
       "      <td>2018-02-08 19:18:34.468038</td>\n",
       "      <td>2018-02-08 19:18:34.468066</td>\n",
       "      <td>The Cost Of The Best Senate Banking Committee ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cost', 'best', 'senat', 'bank', 'committe', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3867639.0</td>\n",
       "      <td>dailycurrant.com</td>\n",
       "      <td>satire</td>\n",
       "      <td>http://dailycurrant.com/2016/01/18/man-awoken-...</td>\n",
       "      <td>Man Awoken From 27-Year Coma Commits Suicide A...</td>\n",
       "      <td>2017-11-27T01:14:21.395055</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Man Awoken From 27-Year Coma Commits Suicide A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['man', 'awoken', '&lt;NUM&gt;', 'year', 'coma', 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9560791.0</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://query.nytimes.com/gst/fullpage.html?re...</td>\n",
       "      <td>WHEN Julia Geist was asked to draw a picture o...</td>\n",
       "      <td>2018-02-11 00:46:42.632962</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>2018-02-11 00:14:20.346871</td>\n",
       "      <td>Opening a Gateway for Girls to Enter the Compu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Computers and the Internet', 'Women and Girl...</td>\n",
       "      <td>WHEN Julia Geist was asked to draw a picture o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>['julia', 'geist', 'ask', 'draw', 'pictur', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2059625.0</td>\n",
       "      <td>infiniteunknown.net</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>http://www.infiniteunknown.net/2011/09/14/100-...</td>\n",
       "      <td>– 100 Compiled Studies on Vaccine Dangers (Act...</td>\n",
       "      <td>2017-11-10T11:18:44.524042</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>100 Compiled Studies on Vaccine Dangers – Infi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lymphoma, Hepatitis B, Immune System, Health, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['&lt;NUM&gt;', 'compil', 'studi', 'vaccin', 'danger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               domain        type  \\\n",
       "0  7444726.0   nationalreview.com   political   \n",
       "1  6213642.0    beforeitsnews.com        fake   \n",
       "2  3867639.0     dailycurrant.com      satire   \n",
       "3  9560791.0          nytimes.com    reliable   \n",
       "4  2059625.0  infiniteunknown.net  conspiracy   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.nationalreview.com/node/152734/%E2%...   \n",
       "1  http://beforeitsnews.com/economy/2012/06/the-c...   \n",
       "2  http://dailycurrant.com/2016/01/18/man-awoken-...   \n",
       "3  https://query.nytimes.com/gst/fullpage.html?re...   \n",
       "4  http://www.infiniteunknown.net/2011/09/14/100-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Plus one article on Google Plus\\n\\n(Thanks to ...   \n",
       "1  The Cost Of The Best Senate Banking Committee ...   \n",
       "2  Man Awoken From 27-Year Coma Commits Suicide A...   \n",
       "3  WHEN Julia Geist was asked to draw a picture o...   \n",
       "4  – 100 Compiled Studies on Vaccine Dangers (Act...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2017-11-27T01:14:42.983556  2018-02-08 19:18:34.468038   \n",
       "1    2017-11-27T01:14:08.7454  2018-02-08 19:18:34.468038   \n",
       "2  2017-11-27T01:14:21.395055  2018-02-07 23:39:33.852671   \n",
       "3  2018-02-11 00:46:42.632962  2018-02-11 00:14:20.346838   \n",
       "4  2017-11-10T11:18:44.524042  2018-02-07 23:39:33.852671   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-08 19:18:34.468066   \n",
       "1  2018-02-08 19:18:34.468066   \n",
       "2  2018-02-07 23:39:33.852696   \n",
       "3  2018-02-11 00:14:20.346871   \n",
       "4  2018-02-07 23:39:33.852696   \n",
       "\n",
       "                                               title authors  keywords  \\\n",
       "0                                 Iran News Round Up     NaN       NaN   \n",
       "1  The Cost Of The Best Senate Banking Committee ...     NaN       NaN   \n",
       "2  Man Awoken From 27-Year Coma Commits Suicide A...     NaN       NaN   \n",
       "3  Opening a Gateway for Girls to Enter the Compu...     NaN       NaN   \n",
       "4  100 Compiled Studies on Vaccine Dangers – Infi...     NaN       NaN   \n",
       "\n",
       "                                       meta_keywords  \\\n",
       "0  ['National Review', 'National Review Online', ...   \n",
       "1                                               ['']   \n",
       "2                                               ['']   \n",
       "3  ['Computers and the Internet', 'Women and Girl...   \n",
       "4                                               ['']   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  WHEN Julia Geist was asked to draw a picture o...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                tags  summary   source  \\\n",
       "0                                                NaN      NaN      NaN   \n",
       "1                                                NaN      NaN      NaN   \n",
       "2                                                NaN      NaN      NaN   \n",
       "3                                                NaN      NaN  nytimes   \n",
       "4  Lymphoma, Hepatitis B, Immune System, Health, ...      NaN      NaN   \n",
       "\n",
       "                                     cleaned content  \n",
       "0  ['plu', 'one', 'articl', 'googl', 'plu', 'than...  \n",
       "1  ['cost', 'best', 'senat', 'bank', 'committe', ...  \n",
       "2  ['man', 'awoken', '<NUM>', 'year', 'coma', 'co...  \n",
       "3  ['julia', 'geist', 'ask', 'draw', 'pictur', 'c...  \n",
       "4  ['<NUM>', 'compil', 'studi', 'vaccin', 'danger...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#DATA_FILE = \"data.csv\"\n",
    "DATA_FILE =\"cleaned_dataset_FULL.csv\"\n",
    "# tvinge pand hele datasættet, før det gætter datatyperne.\n",
    "news_sample = pd.read_csv(DATA_FILE, low_memory=False)\n",
    "news_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Split the resulting dataset into a training, validation, and test splits. A common strategy is to uniformly at random split the data 80% / 10% /\n",
    "10%. You will use the training data to train your baseline and advanced models, the validation data can be used for model selection and\n",
    "hyperparameter tuning, while the test data should only be used in Part 4.\n",
    "\n",
    "\n",
    "Dette program opdeler et renset nyhedsdata-sæt i 80% træning, 10% validering og 10% test ved hjælp af StratifiedShuffleSplit. Det sikrer, at fordelingen af nyhedstyper bevares i alle datasæt, hvilket forbedrer modelens præcision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   object\n",
      "domain               object\n",
      "type                 object\n",
      "url                  object\n",
      "content              object\n",
      "scraped_at           object\n",
      "inserted_at          object\n",
      "updated_at           object\n",
      "title                object\n",
      "authors              object\n",
      "keywords            float64\n",
      "meta_keywords        object\n",
      "meta_description     object\n",
      "tags                 object\n",
      "summary             float64\n",
      "source               object\n",
      "cleaned content      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(news_sample.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vi tejkker om der kolonner i dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'domain', 'type', 'url', 'content', 'scraped_at', 'inserted_at',\n",
      "       'updated_at', 'title', 'authors', 'keywords', 'meta_keywords',\n",
      "       'meta_description', 'tags', 'summary', 'source', 'cleaned content'],\n",
      "      dtype='object')\n",
      "\n",
      " ['political' 'fake' 'satire' 'reliable' 'conspiracy' 'unreliable' 'bias'\n",
      " 'rumor' 'unknown' 'clickbait' 'hate' 'junksci'\n",
      " '2018-02-10 13:43:39.521661']\n"
     ]
    }
   ],
   "source": [
    "print(news_sample.columns)\n",
    "print(\"\\n\", news_sample['type'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fjern mellemrum i kolonnenavne \n",
    "# Fjern rækker med NaN i 'cleaned content' og 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "news_sample.columns = news_sample.columns.str.strip()\n",
    "news_sample = news_sample.dropna(subset=['cleaned content', 'type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal samples i X: 947213\n",
      "Antal labels i y: 947213\n",
      "Fordeling af nyhedstyper:\n",
      " type\n",
      "reliable                      0.230743\n",
      "political                     0.205358\n",
      "bias                          0.140657\n",
      "fake                          0.110728\n",
      "conspiracy                    0.102737\n",
      "rumor                         0.059591\n",
      "unknown                       0.045960\n",
      "unreliable                    0.037301\n",
      "clickbait                     0.028940\n",
      "junksci                       0.014822\n",
      "satire                        0.013893\n",
      "hate                          0.009268\n",
      "2018-02-10 13:43:39.521661    0.000001\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Definer X (features) og y (labels)\n",
    "X = news_sample['cleaned content']\n",
    "y = news_sample['type']\n",
    "# Bekræft, at X og y er defineret korrekt\n",
    "print(f\"Antal samples i X: {len(X)}\")\n",
    "print(f\"Antal labels i y: {len(y)}\")\n",
    "print(\"Fordeling af nyhedstyper:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['political' 'fake' 'satire' 'reliable' 'conspiracy' 'unreliable' 'bias'\n",
      " 'rumor' 'unknown' 'clickbait' 'hate' 'junksci'\n",
      " '2018-02-10 13:43:39.521661']\n"
     ]
    }
   ],
   "source": [
    "# Se de unikke værdier i type-kolonnen\n",
    "print(news_sample['type'].unique())\n",
    "\n",
    "counts = y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Der er en ekra dater på y-gruppen, derfor vi finder de data der er mindre 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find klasser med færre end 2 observationer\n",
    "counts = y.value_counts()\n",
    "classes_to_remove = counts[counts < 2].index\n",
    "mask = ~y.isin(classes_to_remove)\n",
    "\n",
    "X = X[mask]\n",
    "y = y[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vi vill gerne kigge, hviklet kalsser eller kategorier vi har i vorses dat: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "reliable      218563\n",
      "political     194518\n",
      "bias          133232\n",
      "fake          104883\n",
      "conspiracy     97314\n",
      "rumor          56445\n",
      "unknown        43534\n",
      "unreliable     35332\n",
      "clickbait      27412\n",
      "junksci        14040\n",
      "satire         13160\n",
      "hate            8779\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koden køres på rensede data, derfor man skull havede læstet \"cleaned_dataset_FULL.csv\" for at denne del af koden fungere.\n",
    "# Det kræver, at \"scikit-learn\" pakken installeres med: \"pip install scikit-learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataerne der brugt for triaaning, som svar til 80: 757769\n",
      "Dataerne der blive brugt for (validering+ test): 189443 rækker\n",
      "Dataerne der brugt for validering (10%): 94721 rækker\n",
      "Dataerne der blive brugt for test (10%): 94722 rækker\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# Opret StratifiedShuffleSplit objekt\n",
    "split= StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, temp_index in split.split(X, y):\n",
    "    X_train, X_temp = X.iloc[train_index], X.iloc[temp_index]\n",
    "    y_train, y_temp = y.iloc[train_index], y.iloc[temp_index]\n",
    "    \n",
    "\n",
    "# Størrelsen på splits\n",
    "print(f\"Dataerne der brugt for triaaning, som svar til 80: {len(X_train)}\")\n",
    "print(f\"Dataerne der blive brugt for (validering+ test): {len(X_temp)} rækker\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Opret StratifiedShuffleSplit objekt\n",
    "split= StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "for val_index, test_index in split.split(X_temp, y_temp):\n",
    "    X_val, X_test = X_temp.iloc[val_index], X_temp.iloc[test_index]\n",
    "    y_val, y_test = y_temp.iloc[val_index], y_temp.iloc[test_index]\n",
    "\n",
    "# Størrelsen på splits\n",
    "print(f\"Dataerne der brugt for validering (10%): {len(X_val)} rækker\")\n",
    "print(f\"Dataerne der blive brugt for test (10%): {len(X_test)} rækker\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
